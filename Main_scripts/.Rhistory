View(modelNorm3)
# Take the mean of the 10 runs for each world setting
modelNorm3 <- mp %>% # 480 of 5 (cos separate value for each uAuB)
group_by(pgroup, trialtype, node3, uAuB, cond, .drop = FALSE) %>%
summarise(meancesm = mean(cp)) %>%
mutate(intermed = meancesm*cond) %>%
group_by(pgroup, trialtype, node3) %>%
summarise(wa = sum(intermed)) %>%
mutate(normed = wa/sum(wa))
modelNorm <- mp %>% # 288 of 5
group_by(pgroup, trialtype, node3, .drop = FALSE) %>%
summarise(predicted = sum(wa)) %>% # TO DO - what happens if it is mean??
mutate(normpred = predicted/sum(predicted), na.rm = T)
modelNorm <- mp %>% # 288 of 5
group_by(pgroup, trialtype, node3, .drop = FALSE) %>%
summarise(predicted = sum(wa), na.rm = T) %>% # TO DO - what happens if it is mean??
mutate(normpred = predicted/sum(predicted), na.rm = T)
View(modelNorm3)
# Take the mean of the 10 runs for each world setting
modelNorm3 <- mp %>% # 480 of 5 (cos separate value for each uAuB)
group_by(pgroup, trialtype, node3, uAuB, cond, .drop = FALSE) %>%
summarise(meancesm = mean(cp)) %>%
mutate(intermed = meancesm*cond) %>%
group_by(pgroup, trialtype, node3) %>%
summarise(wa = sum(intermed), na.rm = T) %>%
mutate(normed = wa/sum(wa))
View(modelNorm3)
# Take the mean of the 10 runs for each world setting
modelNorm3 <- mp %>% # 480 of 5 (cos separate value for each uAuB)
group_by(pgroup, trialtype, node3, uAuB, cond, .drop = FALSE) %>%
summarise(meancesm = mean(cp)) %>%
mutate(intermed = meancesm*cond) %>%
group_by(pgroup, trialtype, node3) %>%
summarise(wa = sum(intermed)) %>%
mutate(normed = wa/sum(wa), na.rm = T)
View(modelNorm3)
# Take the mean of the 10 runs for each world setting
modelNorm3 <- mp %>% # 480 of 5 (cos separate value for each uAuB)
group_by(pgroup, trialtype, node3, uAuB, cond, .drop = FALSE) %>%
summarise(meancesm = mean(cp)) %>%
mutate(intermed = meancesm*cond) %>%
group_by(pgroup, trialtype, node3) %>% # Now 288
summarise(wa = sum(intermed)) %>%
mutate(normed = wa/sum(wa, na.rm = T))
# An odd little way to bring in realLat status, must be a better way
modelPlaceholder <- mp %>%
na.omit() %>%
group_by(pgroup, trialtype, node3, realLat, .drop = FALSE) %>%
tally
# For realLat, everything TRUE has been defined as such.
# Everything else needs to be FALSE (currently some are na because we used .drop=F to get all the combinations).
modelPlaceholder <- modelPlaceholder %>% replace(is.na(.), FALSE) %>% select(-n)
modelNorm <- merge(modelNorm3, modelPlaceholder)
View(modelNorm)
# A version for NLL - NOT FINISHED YET
combNLL <- merge(x=dataNorm, y=modelNorm) %>%
select(-isPerm, -realLat)
# ----------- 3. The actual merge! ------------
# 576 of 7 -- CLOSEST THING TO SINGLE PREDICTION PER NODE/EXPLANATION
combNorm <- merge(x=dataNorm, y=modelNorm) %>%
select(-predicted, -n) %>% # Probably don't remove - need for lik
rename(cesm=normpred, ppts=prop) %>%
pivot_longer(cols = cesm:ppts, values_to = 'percent')
# ----------- 3. The actual merge! ------------
# 576 of 7 -- CLOSEST THING TO SINGLE PREDICTION PER NODE/EXPLANATION
combNorm <- merge(x=dataNorm, y=modelNorm) %>%
select(-wa, -n) %>% # Probably don't remove - need for lik
rename(cesm=normed, ppts=prop) %>%
pivot_longer(cols = cesm:ppts, values_to = 'percent')
View(combNorm)
# But we also need a version that keeps all the unobserved variables
modelNorm <- mp %>% # 480 of 5 (cos separate value for each uAuB)
group_by(pgroup, trialtype, node3, uAuB, cond, .drop = FALSE) %>%
summarise(meancesm = mean(cp)) %>%
mutate(intermed = meancesm*cond) %>%
group_by(pgroup, trialtype, node3) %>% # Now 288
summarise(wa = sum(intermed)) %>%
mutate(normed = wa/sum(wa, na.rm = T)) %>%
ungroup()
View(modelNorm)
# But we also need a version that keeps all the unobserved variables
modelNorm2 <- mp %>% # 480 of 5 (cos separate value for each uAuB)
group_by(pgroup, trialtype, node3, uAuB, cond, .drop = FALSE) %>%
summarise(meancesm = mean(cp)) %>%
mutate(intermed = meancesm*cond)
View(modelNorm2)
load('../model_data/params.rdata', verbose = T) # defined in script `set_params.r`
# Load functions: world_combos, get_cond_probs, generic_cesm
source('functions.R')
i <- 3
# 1) Get possible world combos of two observed variables in both dis and conj structures
dfd <- world_combos(params = poss_params[[i]], structure = 'disjunctive')
dfd$pgroup <- i
# 2) Get conditional probabilities of these and the two unobserved variables too
newdfd <- get_cond_probs(dfd)
View(dfd)
# 1) Get possible world combos of two observed variables in both dis and conj structures
dfd <- world_combos(params = poss_params[[i]], structure = 'disjunctive')
dfd$pgroup <- i
# 2) Get conditional probabilities of these and the two unobserved variables too
newdfd <- get_cond_probs(dfd)
# Load functions: world_combos, get_cond_probs, generic_cesm
source('functions.R')
# 1) Get possible world combos of two observed variables in both dis and conj structures
dfd <- world_combos(params = poss_params[[i]], structure = 'disjunctive')
dfd$pgroup <- i
# 2) Get conditional probabilities of these and the two unobserved variables too
newdfd <- get_cond_probs(dfd)
View(newdfd)
View(modelNorm)
View(combNorm3)
View(dataNorm)
View(combNLL)
nll <- combNll %>% mutate(nll = log(normed)*n)
nll <- combNLL %>% mutate(nll = log(normed)*n)
View(nll)
nll %>% filter(nll!=c(0,NA))
nll %>% filter(nll!=c(0,NA,Inf))
nll %>% filter(normed!=c(0,NA))
temp <- nll %>% filter(normed!=c(0,NA))
nnewnll <- sum(temp$nll)
e^nnewnll
exp(nnewnll)
sum(nll$n)
288*12
284*12
(1/8)^3408
log(3408/8)
log(1/8)*3408
3408/6
3408/6*5
(0.25^568)*(0.5^2840)
log((0.25^568)*(0.5^2840))
log(0.25)*568+log(0.5)*2840
View(temp)
View(modelNorm)
View(mp)
View(modelNorm2)
modelNorm2 %>% mutate(temp = max(uAuB))
dd <- modelNorm2 %>% ungroup() %>% group_by(pgroup,trialtype,node3) %>% mutate(temp = max(uAuB))
View(dd)
# --------- Lesioning the model -------
# Pick out the 'max permissable 1s' but then we need an index match or some other way to tag the corresponding cesm
dd <- modelNorm2 %>% ungroup() %>% group_by(pgroup,trialtype,node3) %>% summarise(maxuAuB = max(uAuB))
View(dd)
res <- merge(dd, modelNorm2, all.x = T)
View(res)
View(dd)
res <- merge(dd, modelNorm2)
res <- merge(dd, modelNorm2, by.x = maxuAuB, by.y = uAuB)
res <- merge(dd, modelNorm2, by.x = "maxuAuB", by.y = "uAuB")
res <- merge(dd, modelNorm2, by = c("pgroup", "trialtype", "node3"))
View(res)
res <- merge(dd, modelNorm2, by = c("pgroup", "trialtype", "node3")) %>% filter(uAuB==maxuAuB)
res2 <- merge(dd, modelNorm2, by = c("pgroup", "trialtype", "node3")) %>% filter(uAuB==maxuAuB, meancesm!=c(0,NA)) # LOOKS OK
View(res2)
res2 <- merge(dd, modelNorm2, by = c("pgroup", "trialtype", "node3")) %>% filter(meancesm!=c(0,NA)) # LOOKS OK
View(res2)
res3 <- res2 %>% group_by(pgroup,trialtype,node3) %>% summarise(maxuAuB = max(uAuB))
View(res3)
# From that we bring in the model score again
res4 <- merge(res3, modelNorm2, by = c("pgroup", "trialtype", "node3"))
View(res4)
# From that we bring in the model score again
res4 <- merge(res3, modelNorm2, by = c("pgroup", "trialtype", "node3")) %>% filter(uAuB==maxuAuB)
# What we now do is normalise those model predictions. The conditional probabilities can be removed, as can intermed
res4 <- res4 %>% select(-cond, -intermed)
View(res4)
# And now normalise the model score
res4 <- res4 %>%
group_by(pgroup, trialtype) %>%
mutate(normed = meancesm/sum(meancesm))
View(res4)
les <- modelNorm2 %>% group_by(pgroup, trialtype, uAuB)
View(les)
les <- modelNorm2 %>% group_by(pgroup, trialtype, uAuB) %>% summarise(sumcond = sum(cond))
View(les)
les <- modelNorm2 %>% group_by(pgroup, trialtype, uAuB, na.rm = T) %>% summarise(meanmean = mean(meancesm))
View(les)
les <- modelNorm2 %>% group_by(pgroup, trialtype, uAuB) %>% summarise(meanmean = mean(meancesm))
View(les)
les <- modelNorm2 %>% group_by(pgroup, trialtype, uAuB) %>% summarise(meanmean = mean(meancesm)) %>% filter(meanmean!=NA)
View(les)
les <- modelNorm2 %>%
group_by(pgroup, trialtype, uAuB) %>%
summarise(meanmean = mean(meancesm))
View(les)
les <- modelNorm2 %>%
group_by(pgroup, trialtype, uAuB) %>%
summarise(meanmean = mean(meancesm)) %>%
filter(uAuB!='NANA')
View(les)
# Now re-merge back in the cond
les2 <- merge(les, modelNorm2, by= c("pgroup", "trialtype", "uAuB"))
View(les2)
# Now re-merge back in the cond
les2 <- merge(les, modelNorm2$cond, by= c("pgroup", "trialtype", "uAuB"))
View(les2)
View(les)
modelNorm2 %>% group_by(pgroup, trialtype, uAuB) %>% summarise(meancond = mean(cond))
justcond <- modelNorm2 %>%
group_by(pgroup, trialtype, uAuB) %>%
summarise(meancond = mean(cond))
# Now re-merge back in the cond
les2 <- merge(les, justcond, by= c("pgroup", "trialtype", "uAuB")) # STUCK HERE - HOW TO JUST BRING IN COND
View(les2)
# 96 obs of 4
les <- modelNorm2 %>%
group_by(pgroup, trialtype, uAuB) %>%
summarise(meancesm = mean(meancesm)) %>%
filter(uAuB!='NANA')
# Now re-merge back in the cond
les2 <- merge(les, justcond, by= c("pgroup", "trialtype", "uAuB")) # STUCK HERE - HOW TO JUST BRING IN COND
# For each grouping, sample a row according to its conditional probability
sampling <- les2 %>% group_by(pgroup, trialtype) %>% summarise(n=n())
View(sampling)
?sample
sampling$n
length(sampling)
length(res)
nrow(res)
sampling2 <- les2 %>% group_by(pgroup, trialtype) %>% sample(x=1:nrow, size=1, p=meancond)
sampling2 <- les2 %>% group_by(pgroup, trialtype)
View(sampling2)
sampling3 <- sampling2 %>% sample(x=1:nrow, size=1, p=meancond)
sampling3 <- sample(x=1:nrow(sampling2), size=1, p=meancond)
sampling3 <- sample(x=1:nrow(sampling2), size=1, p=sampling2$meancond)
?slice_sample
samp <- slice_sample(data = les2, by = c('pgroup', 'trialtype'), n = 1, weight_by = meancond, with_ties = F)
samp <- slice_sample(les2, by = c('pgroup', 'trialtype'), n = 1, weight_by = meancond, with_ties = F)
samp <- slice_sample(les2, by = c('pgroup', 'trialtype'), n = 1, weight_by = meancond, with_ties = FALSE)
samp <- slice_sample(les2, by = c('pgroup', 'trialtype'), with_ties = FALSE, n = 1, weight_by = meancond)
samp <- slice_sample(.les2, ..., by = c('pgroup', 'trialtype'), with_ties = FALSE, n = 1, weight_by = meancond)
samp <- slice_sample(.les2, 1:nrow(les2), by = c('pgroup', 'trialtype'), with_ties = FALSE, n = 1, weight_by = meancond)
samp <- slice_sample(les2, 1:nrow(les2), by = c('pgroup', 'trialtype'), with_ties = FALSE, n = 1, weight_by = meancond)
samp <- slice_sample(les2, ...=1:nrow(les2), by = c('pgroup', 'trialtype'), with_ties = FALSE, n = 1, weight_by = meancond)
sampling2 <- les2 %>% group_by(pgroup, trialtype) %>% slice_sample(n=1)
View(sampling2)
sampling2 <- les2 %>% group_by(pgroup, trialtype) %>% slice_sample(n=1, weight_by = meancond)
View(sampling2)
# For each grouping, sample a row according to its conditional probability
#sampling <- les2 %>% group_by(pgroup, trialtype) %>% summarise(n=n())
sampling2 <- les2 %>% group_by(pgroup, trialtype) %>% slice_sample(n=1, weight_by = meancond)
# For each grouping, sample a row according to its conditional probability
sampling2 <- les2 %>% group_by(pgroup, trialtype) %>% slice_sample(n=5, weight_by = meancond)
# For each grouping, sample a row according to its conditional probability
sampling2 <- les2 %>% group_by(pgroup, trialtype) %>% slice_sample(n=5, weight_by = meancond)
# For each grouping, sample a row according to its conditional probability
sampling2 <- les2 %>% group_by(pgroup, trialtype) %>% slice_sample(n=10, weight_by = meancond)
View(sampling2)
# For each grouping, sample a row according to its conditional probability
sampling3 <- les2 %>% group_by(pgroup, trialtype) %>% slice_sample(n=10, weight_by = meancond)
# For each grouping, sample a row according to its conditional probability
sampling <- les2 %>% group_by(pgroup, trialtype) %>% slice_sample(n=1, weight_by = meancond)
View(sampling)
?replicate
replicate(5, les2 %>% group_by(pgroup, trialtype) %>% slice_sample(n=1, weight_by = meancond))
les2 %>% group_by(pgroup, trialtype) %>% replicate(5, slice_sample(n=1, weight_by = meancond), simplify = 'array')
les2 %>% group_by(pgroup, trialtype) %>% replicate(n=5, expr = slice_sample(n=1, weight_by = meancond), simplify = 'array')
myFun <- function(df) {
samp <- df %>%
group_by(pgroup, trialtype) %>%
slice_sample(n=1, weight_by = meancond)
samp
}
myFun(les2)
fun1 <- function(n = 10) replicate(n, myFun(les2))
View(fun1)
fun1(df)
fun1 <- function(n = 10) {replicate(n, myFun(les2))}
fun1 <- function() {replicate(n, myFun(les2))}
fun1 <- function() {replicate(n, myFun())}
fun1(les2)
ls <- replicate(10, myFun(les2)) # not working
View(ls)
ls <- replicate(10, myFun(les2)) %>% unlist()
ls <- as.data.frame(replicate(10, myFun(les2)))
View(ls)
ls <- replicate(10, myFun(les2), simplify = 'array') # This does same as
View(ls)
simplify2array(ls)
df <- data.frame(rep(NA, 36))
for (i in ls) {
cbind(df, i)
}
View(df)
ls
View(ls)
ls[[1]]
ls[1,1]
length(ls)
ls <- replicate(10, myFun(les2)) # This does same as --- , simplify = 'array'
length(ls)
ls[[1]]
ls[1,1]
ls[1,1]
df <- data.frame(rep(NA, 36))
ls[[50]]
ls[[49]]
for (i in 1:length(ls)) {
cbind(df, ls[[i]])
}
View(df)
df <- data.frame(rep(NA, 36))
View(df)
df <- rep(NA, 36)
rbind(df, ls[[i]])
df
df1 <- for (i in 1:length(ls)) {
rbind(df, ls[[i]])
}
pl <- data.frame(matrix(ncol = 36, nrow = 0))
for (i in 1:length(ls)) {
j <- ls[[i]]
rbind(pl, j)
}
View(pl)
pl[[1]]
ls[[1]]
ls[[1]][[1]]
f <- ls[[1]]
f <- ls[[50]]
i <- 50
j <- ls[[i]]
View(pl)
View(ls)
ls[1,]
ls[,1]
n <- 10
ls <- replicate(n, myFun(les2)) # This does same as --- , simplify = 'array'
for (i in 1:length(ls)) {
j <- ls[[,i]]
for (g in 1:length(j)) {
rbind(pl, g)
}
}
pl <- data.frame(matrix(ncol = 0, nrow = 36))
for (i in 1:length(ls)) {
j <- ls[[,i]]
for (g in 1:length(j)) {
rbind(pl, g)
}
}
for (i in 1:length(ls)) {
j <- ls[[,i]]
for (g in 1:length(j)) {
cbind(pl, g)
}
}
for (i in 1:length(n)) {
j <- ls[[,i]]
for (g in 1:length(j)) {
cbind(pl, g)
}
}
length(n)
1:n
for (i in 1:n) {
j <- ls[[,i]]
for (g in 1:length(j)) {
cbind(pl, g)
}
}
i <- 1
j <- ls[[,i]]
j <- ls[,i]
g <- 1
j[1]
h <- j[1]
cbind(pl, h)
for (i in 1:n) {
j <- ls[,i]
for (g in 1:length(j)) {
h <- j[1]
cbind(pl, h)
}
}
for (i in 1:n) {
j <- ls[,i]
for (g in 1:length(j)) {
h <- j[1]
pl <- cbind(pl, h)
}
}
View(pl)
for (i in 1:n) {
j <- ls[,i]
for (g in 1:length(j)) {
h <- j[g]
pl <- cbind(pl, h)
}
}
pl <- data.frame(matrix(ncol = 0, nrow = 36))
for (i in 1:n) {
j <- ls[,i]
for (g in 1:length(j)) {
h <- j[g]
pl <- cbind(pl, h)
}
}
View(pl)
# Remove some useless columns
pl <- pl %>% select(-c(6,7,11,12,16,17,21,22,26,27,31,32,36,37,41,42,46,47))
# Remove some useless columns
pl <- pl %>% select(-6,-7,-11,-12,-16,-17,-21,-22,-26,-27,-31,-32,-36,-37,-41,-42,-46,-47))
# Remove some useless columns
pl <- pl %>% select(-6,-7,-11,-12,-16,-17,-21,-22,-26,-27,-31,-32,-36,-37,-41,-42,-46,-47)
# Remove some useless columns #,-7,-11,-12,-16,-17,-21,-22,-26,-27,-31,-32,-36,-37,-41,-42,-46,-47
pl <- pl %>% select(-6)
View(les2)
df <- les2
samp2 <- df[,1:3]
View(samp2)
# A function to sample by slice_sample a setting of uAuB from each trialtype in each pgroup, by its conditional probability
myFun <- function(df) {
samp <- df %>%
group_by(pgroup, trialtype) %>%
slice_sample(n=1, weight_by = meancond)
samp2 <- samp[,1:3]
samp2
}
# Run this function n times (change n if you like)
n <- 10
ls <- replicate(n, myFun(les2))
View(ls)
# Empty place to store the results
pl <- data.frame(matrix(ncol = 0, nrow = 36))
ls[1,]
ls[1][1]
ls[,1][1]
pl <- cbind(pl, ls[,1][1])
View(pl)
ls[,2][1]
ls[,][2]
pl <- cbind(pl, ls[,1][1], ls[,1][2])
# Empty place to store the results
pl <- data.frame(matrix(ncol = 0, nrow = 36))
pl <- cbind(pl, ls[,1][1], ls[,1][2])
for (i in 1:n) {
j <- ls[,i]
h <- j[3]
pl <- cbind(pl, h)
}
View(pl)
pl2 <- pl %>% pivot_longer(cols = -c(pgroup, trialtype), names_to = c('run', 'unobs'),
names_sep = '.') # Gives 768 of 15 vars (126 for each of 6 probgroups)
View(pl2)
pl2 <- pl %>% pivot_longer(cols = -c(pgroup, trialtype), names_sep = '.') # Gives 768 of 15 vars (126 for each of 6 probgroups)
pl2 <- pl %>% pivot_longer(cols = -c(pgroup, trialtype)) # Gives 768 of 15 vars (126 for each of 6 probgroups)
View(pl2)
# Pivot long
pl2 <- pl %>% pivot_longer(cols = -c(pgroup, trialtype)) %>% select(-name)
View(pl2)
# Remove
pl2 <- pl2 %>% group_by(pgroup, trialtype, value) %>% summarise(n=n())
View(modelNorm2)
View(res4)
View(res4)
View(modelNorm2)
les3 <- modelNorm2 %>%
group_by(pgroup, trialtype, node3, uAuB) %>%
summarise(meancesm = mean(meancesm)) %>%
filter(uAuB!='NANA')
View(les3)
justcond <- modelNorm2 %>%
group_by(pgroup, trialtype, node3, uAuB) %>%
summarise(meancond = mean(cond))
View(justcond)
les4 <- merge(les3, justcond, by= c("pgroup", "trialtype", "node3", "uAuB"))
View(les4)
# A function to sample by slice_sample a setting of uAuB from each trialtype in each pgroup, by its conditional probability
myFun <- function(df) {
samp <- df %>%
group_by(pgroup, trialtype, node3) %>%
slice_sample(n=1, weight_by = meancond)
samp2 <- samp[,1:4]
samp2
}
# Run this function n times (change n if you like)
n <- 10
ls <- replicate(n, myFun(les4))
# Empty place to store the results
pl <- data.frame(matrix(ncol = 0, nrow = 36))
# But with the first two bits as standards
pl <- cbind(pl, ls[,1][1], ls[,1][2], ls[,1][3])
dim(ls)
View(les4)
View(les2)
View(df)
View(dd)
View(les4)
# Empty place to store the results
pl <- data.frame(matrix(ncol = 0, nrow = 192)) # 36 if no node3; 192 if yes
# But with the first two bits as standards
pl <- cbind(pl, ls[,1][1], ls[,1][2], ls[,1][3])
View(pl)
# Now get samples into a df
for (i in 1:n) {
j <- ls[,i]
h <- j[4]
pl <- cbind(pl, h)
}
View(pl)
View(pl)
# Pivot long
pl2 <- pl %>% pivot_longer(cols = -c(pgroup, trialtype, node3)) %>% select(-name)
View(pl2)
# Remove
pl2 <- pl2 %>% group_by(pgroup, trialtype, node3, value) %>% summarise(n=n())
View(pl2)
?version
R.version
